# Task 1: Introduction to CUDA Python with Numba

## Часть 1: Введение в CUDA Python с Numba

### Что такое Numba?

Numba — это **just-in-time** (JIT), **type-specializing**, **function compiler** для ускорения **численно-ориентированного** Python-кода на CPU или GPU.

- **Function compiler** — Numba компилирует отдельные Python-функции, а не целые приложения. Numba не заменяет интерпретатор Python, а просто превращает функцию в (обычно) более быструю функцию.
- **Type-specializing** — Numba ускоряет функции, генерируя специализированную реализацию для конкретных типов данных, с которыми вы работаете. Python-функции спроектированы для работы с обобщёнными типами данных, что делает их гибкими, но медленными.
- **Just-in-time** — Numba транслирует функции при первом вызове, что позволяет компилятору знать типы аргументов. Это также позволяет использовать Numba интерактивно в Jupyter notebook.
- **Numerically-focused** — Numba ориентирована на числовые типы данных: `int`, `float`, `complex`. Поддержка строк ограничена. Для лучших результатов рекомендуется использовать массивы NumPy.

### Сравнение: CUDA C/C++ vs Numba vs pyCUDA

| Характеристика | CUDA C/C++ | pyCUDA | Numba |
|---|---|---|---|
| Производительность | Наивысшая | Высокая (вся CUDA C/C++ API) | Потенциально чуть ниже pyCUDA |
| Язык | C/C++ | Python + C-вставки | Чистый Python |
| Простота использования | Сложно | Требует написания C-кода в Python | Минимальные изменения кода |
| Применение | Ускорение C/C++ приложений | GPU-ускорение Python | GPU-ускорение Python + оптимизация для CPU |

### Компиляция для CPU с декоратором `@jit`

Декоратор `@jit` компилирует Python-функцию для CPU:

```python
from numba import jit
import math

@jit
def hypot(x, y):
    x = abs(x)
    y = abs(y)
    t = min(x, y)
    x = max(x, y)
    t = t / x
    return x * math.sqrt(1 + t * t)
```

При первом вызове `hypot(3.0, 4.0)` Numba компилирует машинный код для float-входов. Оригинальная Python-реализация доступна через `.py_func`.

### Как работает Numba (процесс компиляции)

При первом вызове Numba-обёрнутой функции запускается процесс:

1. **Bytecode analysis** — Numba анализирует байт-код Python-функции
2. **Type inference** — определяет типы всех переменных
3. **Lowering to LLVM IR** — транслирует в промежуточное представление LLVM
4. **Machine code generation** — генерирует машинный код

Результат вывода типов можно посмотреть через `.inspect_types()`.

**Важно:** Типы Numba соответствуют типам NumPy: Python `float` → `float64` (double precision). Производительность `float32` и `float64` на GPU может сильно различаться. Если алгоритм работает корректно с `float32`, используйте его — приведение к `float64` может значительно замедлить выполнение.

### Object mode и nopython mode

- **Object mode** — режим по умолчанию. Если Numba не может скомпилировать код (например, словари), она «откатывается» в этот режим без специализации типов.
- **nopython mode** — рекомендуемый режим. Вызывает ошибку, если код не может быть полностью скомпилирован. Включается через `@jit(nopython=True)` или декоратор `@njit`.

```python
from numba import njit

@njit  # эквивалент @jit(nopython=True)
def my_function(x):
    return x * 2
```

**Использование `nopython` mode — лучшая практика, обеспечивающая максимальную производительность.**

### GPU-ускорение с NumPy Universal Functions (ufuncs)

GPU-оборудование спроектировано для **параллелизма данных** (data parallelism). Максимальная пропускная способность достигается, когда GPU выполняет одинаковые операции над множеством элементов одновременно.

NumPy ufuncs выполняют одну и ту же операцию поэлементно над массивом — они идеально подходят для GPU.

### Создание GPU ufuncs с `@vectorize`

Для компиляции ufunc для GPU используется декоратор `@vectorize` с **явной сигнатурой типа** и `target='cuda'`:

```python
from numba import vectorize

@vectorize(['int64(int64, int64)'], target='cuda')
def add_ufunc(x, y):
    return x + y
```

При вызове `add_ufunc(a, b)` Numba автоматически:
1. Компилирует CUDA-ядро для параллельного выполнения
2. Выделяет GPU-память для входных и выходных данных
3. Копирует входные данные на GPU
4. Выполняет CUDA-ядро с правильными размерностями
5. Копирует результат обратно с GPU на CPU
6. Возвращает результат как NumPy-массив

### Когда GPU медленнее CPU

GPU может быть медленнее CPU если:
- **Входные данные слишком малы** — GPU достигает производительности через параллелизм (тысячи элементов одновременно)
- **Вычисления слишком просты** — накладные расходы на отправку задачи на GPU превышают экономию
- **Копирование данных** — передача данных между CPU и GPU занимает время
- **Типы данных слишком большие** — `float64` может быть в 2–24 раза медленнее `float32` на GPU в зависимости от архитектуры

### CUDA Device Functions

Для вспомогательных функций, вызываемых из GPU-кода, используется `@cuda.jit(device=True)`:

```python
from numba import cuda

@cuda.jit(device=True)
def polar_to_cartesian(rho, theta):
    x = rho * math.cos(theta)
    y = rho * math.sin(theta)
    return x, y
```

Device-функции могут вызываться **только** из кода, работающего на GPU. Компилятор CUDA агрессивно встраивает (inline) device-функции — накладных расходов на вызов практически нет.

### Допустимый Python-код на GPU

На GPU поддерживаются:
- `if`/`elif`/`else`
- Циклы `while` и `for`
- Базовые математические операции
- Функции из модулей `math` и `cmath`
- Кортежи (tuples)

**Важно:** На GPU используются скалярные функции из модуля `math`, а не из NumPy.

### Управление GPU-памятью

Рекомендация из CUDA Best Practices Guide:
> **Высокий приоритет:** Минимизируйте передачу данных между хостом (CPU) и устройством (GPU), даже если это означает запуск некоторых ядер на GPU без прироста производительности.

#### CUDA Device Arrays

Для предотвращения автоматического копирования данных обратно на хост создаются **CUDA Device Arrays**:

```python
from numba import cuda
import numpy as np

x_device = cuda.to_device(x)         # копирование на GPU
y_device = cuda.to_device(y)         # копирование на GPU
out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # выделение памяти на GPU

add_ufunc(x_device, y_device, out=out_device)  # операция на GPU без копирования

out_host = out_device.copy_to_host()  # явное копирование обратно на CPU
```

Такой подход устраняет ненужные передачи данных между хостом и устройством.

### Обобщённые ufuncs (gufuncs)

Обычные ufuncs выполняют скалярные операции поэлементно. Обобщённые ufuncs (`@guvectorize`) позволяют работать с массивами более низкой размерности и проецировать их на массивы более высокой размерности:

```python
from numba import guvectorize

@guvectorize(['(float32[:], float32[:])'], '(i)->()', target='cuda')
def l2_norm(vec, out):
    acc = 0.0
    for value in vec:
        acc += value**2
    out[0] = math.sqrt(acc)
```

---

## Часть 2: Пользовательские CUDA-ядра в Python с Numba

### Зачем нужны пользовательские ядра?

Ufuncs элегантны для поэлементных операций, но многие задачи не могут быть выражены через ufunc: стенсильные алгоритмы, редукции и любые задачи, требующие доступа к нескольким элементам одновременно.

Пользовательские CUDA-ядра (kernels) дают разработчикам огромную гибкость и контроль над параллелизмом, явно используя иерархию потоков CUDA.

### Введение в CUDA-ядра

- **Kernel** — функция, запускаемая на множестве ядер GPU параллельно в **потоках** (threads)
- **Execution configuration** (launch configuration) — описывает конфигурацию параллельного запуска
- Потоки организованы в **блоки** (blocks), блоки — в **сетку** (grid)

### Написание первого CUDA-ядра

```python
from numba import cuda

@cuda.jit
def add_kernel(x, y, out):
    idx = cuda.grid(1)  # уникальный индекс потока в 1D-сетке
    out[idx] = x[idx] + y[idx]
```

Запуск ядра:
```python
threads_per_block = 64
blocks_per_grid = 32
add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)
cuda.synchronize()
```

**Ключевые моменты:**
- `@cuda.jit` — декоратор для CUDA-ядер (не путать с `@jit` для CPU)
- `cuda.grid(1)` — удобная функция, эквивалентная `cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x`
- CUDA-ядра **не возвращают значений** — результат записывается в выходной массив
- Явная сигнатура типа **не требуется**

### Streaming Multiprocessors и скрытие латентности

GPU NVIDIA состоят из нескольких **Streaming Multiprocessors (SM)**. При запуске ядра каждый блок назначается одному SM. SM разделяет блоки на подгруппы по 32 потока — **warps**.

Когда инструкция занимает более одного такта, SM может продолжать работу, если есть другие warps, готовые принять новые инструкции. Переключение контекста между warps **не имеет штрафа по времени** благодаря большим файлам регистров.

**Главный принцип:** для полной утилизации GPU необходимо обеспечить SM достаточным количеством warps — через большие размеры сетки и блоков.

Рекомендации по размеру:
- Размер блока — кратный 32 (размер warp), типично 128–512 потоков
- Количество блоков — 2x–4x количества SM на GPU (начинать с 20–100 блоков)

### Grid Stride Loops

Когда данных больше, чем потоков в сетке, каждый поток обрабатывает несколько элементов через **grid stride loop**:

```python
@cuda.jit
def add_kernel(x, y, out):
    start = cuda.grid(1)          # стартовый индекс потока
    stride = cuda.gridsize(1)     # общее количество потоков в сетке

    for i in range(start, x.shape[0], stride):
        out[i] = x[i] + y[i]
```

Преимущества grid stride loop:
- Гибкость — одно ядро работает с данными любого размера
- **Memory coalescing** — параллельные потоки обращаются к памяти последовательно, что позволяет GPU сокращать общее число операций с памятью

### Атомарные операции и race conditions

**Race condition** (состояние гонки) возникает, когда потоки одновременно читают/записывают в одну ячейку памяти:
- **Read-after-write** — один поток читает, другой одновременно пишет
- **Write-after-write** — два потока пишут в одну ячейку

Стратегии избежания:
1. Каждый поток отвечает за уникальное подмножество выходных элементов
2. Не использовать один массив как вход и выход одновременно
3. Использовать **атомарные операции** — чтение, модификация и запись в одном неделимом шаге

```python
@cuda.jit
def thread_counter_safe(global_counter):
    cuda.atomic.add(global_counter, 0, 1)  # атомарное сложение
```

Без атомарной операции `global_counter[0] += 1` приведёт к неправильному результату из-за race condition.

### Генерация случайных чисел на GPU

Numba включает генератор `xoroshiro128+` с периодом 2^128 - 1:

```python
from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32

rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)

@cuda.jit
def monte_carlo_mean(rng_states, iterations, out):
    thread_id = cuda.grid(1)
    total = 0
    for i in range(iterations):
        sample = xoroshiro128p_uniform_float32(rng_states, thread_id)
        total += sample
    out[thread_id] = total / iterations
```

Каждое состояние инициализируется в одной последовательности (по seed), но разделено на 2^64 шагов — разные потоки не пересекаются.

### Отладка CUDA-кода

1. **Печать (`print`)** — Numba поддерживает печать из CUDA-ядер (только постоянные строки и скаляры, без форматирования)
2. **CUDA Simulator** — режим `NUMBA_ENABLE_CUDASIM=1`, выполняющий CUDA-код на CPU через Python-интерпретатор. Позволяет использовать `pdb` для отладки
3. **cuda-memcheck** — утилита из полного CUDA Toolkit, находит ошибки доступа к памяти. Использование `@cuda.jit(debug=True)` добавляет информацию о строке в ошибки

---

## Часть 3: Эффективное использование памяти GPU

### Проблема: некоалесцентный доступ к памяти

**Coalesced memory access** (коалесцентный доступ) — когда соседние потоки в warp обращаются к соседним ячейкам памяти. Это позволяет GPU объединять обращения в одну транзакцию.

При коалесцентном доступе:
```python
out[i] = a[i] + b[i]  # потоки 0,1,2,... читают элементы 0,1,2,...
```

При некоалесцентном доступе (с шагом `stride`):
```python
out[i] = a[stride * i] + b[stride * i]  # потоки 0,1,2,... читают элементы 0,16,32,...
```

Некоалесцентный доступ может быть в **2–3 раза медленнее**.

### Глобальная память GPU

Глобальная память — основная память GPU, доступная всем потокам и блокам. Обращения к ней происходят через **сегменты** фиксированного размера. Когда потоки warp'а обращаются к соседним адресам — одна транзакция обслуживает все запросы. При разрозненных обращениях — множество транзакций.

### Двумерные и трёхмерные блоки и сетки

Блоки и сетки могут быть 2D или 3D — это удобно для работы с матрицами:

```python
blocks = (2, 2)
threads_per_block = (2, 2)

@cuda.jit
def get_2D_indices(A):
    x, y = cuda.grid(2)  # 2D-индексы потока
    A[x][y] = x + y / 10
```

**Для коалесцентного доступа к матрицам:** `threadIdx.x` должен соответствовать самому быстро меняющемуся индексу (столбцу в C-style массивах):
```python
# Коалесцентный доступ:
out[y][x] = a[y][x] + b[y][x]

# Некоалесцентный доступ:
out[x][y] = a[x][y] + b[x][y]
```

### Shared Memory (общая память)

**Shared memory** — быстрая, программно управляемая кеш-память на чипе GPU:
- Общая между всеми потоками **одного блока**
- Ограниченный размер (зависит от GPU)
- Не доступна потокам других блоков
- Не сохраняется после завершения ядра
- **Гораздо более высокая пропускная способность**, чем у глобальной памяти

Применения shared memory:
1. Кеширование данных из глобальной памяти при многократном чтении
2. Буферизация вывода потоков для коалесцентной записи в глобальную память
3. Промежуточное хранение для scatter/gather операций внутри блока

### Синтаксис shared memory в Numba

```python
from numba import types

@cuda.jit
def swap_with_shared(vector, swapped):
    temp = cuda.shared.array(4, dtype=types.int32)  # выделение shared memory
    idx = cuda.grid(1)
    
    temp[idx] = vector[idx]       # запись в shared memory
    cuda.syncthreads()            # синхронизация всех потоков в блоке
    swapped[idx] = temp[3 - cuda.threadIdx.x]  # чтение из shared memory
```

**`cuda.syncthreads()`** — обязательная синхронизация перед чтением данных, записанных другими потоками.

**Важно:** Размер shared-массива должен быть **константой** — нельзя использовать аргументы функции или `blockDim`.

### Shared Memory для коалесцентной транспозиции матрицы

Наивная транспозиция: коалесцентное чтение, но некоалесцентная запись:
```python
transposed[x][y] = a[y][x]  # чтение коалесцентно, запись — нет
```

Оптимизированная транспозиция через shared memory:
1. Коалесцентно прочитать тайл из входной матрицы в shared memory
2. Синхронизировать потоки
3. Коалесцентно записать транспонированный тайл из shared memory в выходную матрицу

```python
@cuda.jit
def tile_transpose(a, transposed):
    temp = cuda.shared.array((32, 32), dtype=types.int32)
    
    a_col = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x
    a_row = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y
    
    temp[cuda.threadIdx.y, cuda.threadIdx.x] = a[a_row, a_col]  # коалесцентное чтение
    cuda.syncthreads()
    
    t_col = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.x
    t_row = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.y
    
    transposed[t_row, t_col] = temp[cuda.threadIdx.x, cuda.threadIdx.y]  # коалесцентная запись
```

### Bank Conflicts в shared memory

Shared memory разделена на **банки** (обычно 32). Когда два потока одного warp обращаются к разным адресам в одном банке — происходит **bank conflict**, и обращения сериализуются.

**Решение:** добавить padding к shared-массиву, чтобы сместить адреса:
```python
# Вместо (32, 32) используем (32, 33) — лишний столбец для устранения bank conflicts
tile = cuda.shared.array((32, 33), numba_types.float32)
```

Это простое изменение устраняет bank conflicts и даёт дополнительное ускорение.

---

## Вопросы и ответы

**1. Что такое Numba и для чего она используется?**

Numba — это JIT-компилятор для Python, который специализируется на типах данных и компилирует функции для ускорения численно-ориентированного кода. Numba может компилировать функции как для CPU, так и для GPU (NVIDIA CUDA). Она особенно полезна для ускорения операций над массивами NumPy без необходимости писать код на C/C++.

**2. В чём разница между object mode и nopython mode в Numba?**

В object mode Numba не выполняет специализацию типов и работает через Python-объекты — это медленно. В nopython mode Numba полностью компилирует функцию в машинный код, и если какая-то часть не может быть скомпилирована, выбрасывается ошибка. Рекомендуется всегда использовать nopython mode (через `@njit` или `@jit(nopython=True)`), так как он обеспечивает максимальную производительность.

**3. Как создать GPU-ускоренную ufunc с помощью Numba?**

Для этого используется декоратор `@vectorize` с явной сигнатурой типов и параметром `target='cuda'`. Например: `@vectorize(['float32(float32, float32)'], target='cuda')`. Функция описывает скалярную операцию, а Numba автоматически применяет её параллельно ко всем элементам массива на GPU.

**4. Почему GPU может быть медленнее CPU для простых операций на маленьких массивах?**

Потому что GPU достигает производительности через массивный параллелизм — ему нужны тысячи элементов для обработки. На маленьких массивах накладные расходы на отправку данных на GPU, запуск ядра и копирование результата обратно превышают выигрыш от параллелизма. Также простые вычисления (низкая арифметическая интенсивность) не могут компенсировать эти накладные расходы.

**5. Что такое CUDA Device Array и зачем он нужен?**

CUDA Device Array — это массив, размещённый в памяти GPU. Он создаётся через `cuda.to_device()` или `cuda.device_array()`. Его преимущество в том, что данные остаются на GPU между вызовами ядер, исключая ненужные копирования между CPU и GPU. Это критически важно для производительности, когда нужно выполнить последовательность GPU-операций.

**6. Чем CUDA-ядро отличается от GPU ufunc?**

GPU ufunc (`@vectorize`) выполняет одинаковую скалярную операцию над каждым элементом массива. CUDA-ядро (`@cuda.jit`) даёт полный контроль над параллелизмом: можно обращаться к нескольким элементам, использовать разные стратегии индексирования, shared memory, атомарные операции. Ядра не возвращают значений — результат записывается в выходной массив.

**7. Что такое grid stride loop и зачем он нужен?**

Grid stride loop — это паттерн, при котором каждый поток начинает с индекса, равного своему глобальному индексу в сетке, и затем шагает на размер всей сетки. Это позволяет обрабатывать массивы, размер которых больше числа потоков в сетке, сохраняя при этом коалесцентный доступ к памяти. Формула: `for i in range(cuda.grid(1), data.shape[0], cuda.gridsize(1))`.

**8. Что такое race condition в CUDA и как её избежать?**

Race condition — это ситуация, когда несколько потоков одновременно обращаются к одной ячейке памяти, и хотя бы один из них записывает данные. Результат непредсказуем. Основные способы избежать: (1) дать каждому потоку эксклюзивную ответственность за свою часть данных, (2) использовать атомарные операции, например `cuda.atomic.add()`, которые выполняют чтение-модификацию-запись как одну неделимую операцию.

**9. Что такое coalesced memory access и почему он важен?**

Coalesced (коалесцентный) доступ к памяти — это когда соседние потоки warp'а (32 потока) обращаются к соседним ячейкам глобальной памяти. GPU может объединить такие обращения в одну транзакцию. При некоалесцентном доступе (когда потоки обращаются к разрозненным адресам) требуется больше транзакций, что может замедлить выполнение в 2–3 раза.

**10. Что такое shared memory и в каких случаях она используется?**

Shared memory — это быстрая, ограниченная по размеру память на чипе GPU, разделяемая между всеми потоками одного блока. Она используется для: кеширования данных из глобальной памяти при многократном чтении, буферизации данных для обеспечения коалесцентной записи в глобальную память, обмена данными между потоками одного блока. Пропускная способность shared memory значительно выше, чем у глобальной памяти.

**11. Зачем нужен `cuda.syncthreads()` при работе с shared memory?**

`cuda.syncthreads()` — это барьер синхронизации, который заставляет все потоки в блоке дождаться, пока все остальные потоки достигнут этой точки. Это необходимо при работе с shared memory, потому что один поток может читать данные, которые должен записать другой поток. Без синхронизации поток может прочитать устаревшие или неинициализированные данные.

**12. Что такое bank conflict в shared memory и как его устранить?**

Shared memory состоит из 32 банков. Bank conflict возникает, когда два или более потока одного warp'а одновременно обращаются к разным адресам в одном и том же банке — обращения сериализуются. Классический способ устранения — добавить padding: вместо массива `(32, 32)` использовать `(32, 33)`, что сдвигает адреса и исключает конфликты.

**13. Какой размер блока рекомендуется использовать при запуске CUDA-ядер?**

Размер блока должен быть кратен 32 (размер warp'а). Типичный диапазон — от 128 до 512 потоков на блок. Количество блоков в сетке должно быть достаточным для полной загрузки GPU — рекомендуется 2–4 кратное количество SM на GPU (обычно 20–100 блоков для начала). Слишком малые размеры не позволяют GPU скрывать латентность, а слишком большое количество блоков увеличивает накладные расходы на запуск.

**14. Как оптимизировать транспозицию матрицы на GPU с помощью shared memory?**

Наивная транспозиция делает коалесцентные чтения, но некоалесцентные записи. Оптимизация: (1) коалесцентно загрузить тайл 32×32 из входной матрицы в shared memory, (2) синхронизировать потоки, (3) коалесцентно записать транспонированные элементы из shared memory в выходную матрицу. Дополнительно, использование размера `(32, 33)` вместо `(32, 32)` для shared-массива устраняет bank conflicts.

**15. Какие ограничения Python-кода существуют на GPU в Numba?**

На GPU в Numba поддерживаются: условные конструкции (`if`/`elif`/`else`), циклы (`while`, `for`), базовые математические операции, выбранные функции из модулей `math` и `cmath`, кортежи. Не поддерживаются: словари, строковые операции, большинство стандартных Python-библиотек. Для математических функций необходимо использовать модуль `math`, а не NumPy.
