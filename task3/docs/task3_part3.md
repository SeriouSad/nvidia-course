# Task 3, Часть 3: Машинное обучение с GPU-ускорением (cuML, XGBoost, Triton, Dask)

## Контекст задачи

В этой части мы работаем с данными о населении Великобритании. У нас есть координаты проживания людей (`easting`, `northing`), их возраст (`age`), пол (`sex`) и информация о том, заражён ли человек симулированным вирусом (`infected`). Наша цель — применить различные алгоритмы машинного обучения на GPU для:

- кластеризации населения по географии
- предсказания вероятности заражения
- поиска ближайших объектов
- развёртывания обученной модели в продакшене
- масштабирования на несколько GPU

Все алгоритмы ускорены на GPU через библиотеку **cuML** (часть экосистемы RAPIDS), а данные хранятся и обрабатываются в **cuDF** (GPU-аналог pandas).

---

## 1. K-Means — кластеризация населения

### Что мы делали

Загрузили координаты населения (`easting`, `northing`) и применили алгоритм K-Means, чтобы найти оптимальные позиции для 5 (а затем 6) гуманитарных складов для сброса грузов с воздуха. Идея: разделить всё население на K групп по географической близости, чтобы каждый склад обслуживал свою зону.

```python
import cudf
import cuml

gdf = cudf.read_csv('./data/clean_uk_pop.csv', usecols=['easting', 'northing'])

km = cuml.KMeans(n_clusters=5)
km.fit(gdf)

gdf['cluster'] = km.labels_         # метка кластера для каждого человека
centers = km.cluster_centers_        # координаты центров (= позиции складов)
```

### Как работает K-Means

K-Means — алгоритм кластеризации **без учителя** (unsupervised). Он не требует заранее размеченных данных — только число кластеров K.

**Алгоритм:**
1. Случайно выбрать K начальных центроидов
2. **Назначение** — каждую точку отнести к ближайшему центроиду
3. **Обновление** — пересчитать центроиды как среднее всех точек в кластере
4. Повторять шаги 2–3 до сходимости (центроиды перестают двигаться)

**Почему это работает на GPU:**
Шаг назначения — это вычисление расстояний от каждой точки до каждого центроида. При миллионах точек это огромное количество независимых вычислений, которые GPU выполняет параллельно. Шаг обновления — это вычисление средних по группам, что тоже хорошо параллелизуется.

**Особенности:**
- K задаётся заранее — алгоритм не определяет «правильное» число кластеров
- Результат зависит от начальной инициализации (cuML использует умную инициализацию `k-means++`)
- Кластеры имеют сферическую форму (оптимизирует евклидово расстояние)

### Визуализация

Для отображения результатов использовался `cuxfilter` — библиотека для интерактивных GPU-дашбордов:

```python
import cuxfilter as cxf

cxf_data = cxf.DataFrame.from_dataframe(gdf)
scatter_chart = cxf.charts.datashader.scatter(x='easting', y='northing')
cluster_widget = cxf.charts.panel_widgets.multi_select('cluster')

dash = cxf_data.dashboard(charts=[scatter_chart], sidebar=[cluster_widget])
dash.app()
```

`cuxfilter` работает напрямую с GPU-данными — не нужно копировать миллионы точек на CPU.

---

## 2. DBSCAN — поиск очагов заражения

### Что мы делали

Отфильтровали только заражённых людей (`infected == 1`) и применили DBSCAN, чтобы найти географические кластеры заражения — потенциальные очаги распространения вируса от «нулевых пациентов».

```python
dbscan = cuml.DBSCAN(eps=5000)

infected_df = gdf[gdf['infected'] == 1].reset_index()
infected_df['cluster'] = dbscan.fit_predict(infected_df[['northing', 'easting']])
n_clusters = infected_df['cluster'].nunique()
```

### Как работает DBSCAN

DBSCAN (Density-Based Spatial Clustering of Applications with Noise) — алгоритм кластеризации, основанный на **плотности**.

**Ключевые параметры:**
- `eps` — радиус окрестности. Точки на расстоянии ≤ eps считаются соседями
- `min_samples` — минимальное число соседей для «ядровой» точки (по умолчанию 5)

**Алгоритм:**
1. **Поиск ядровых точек** — точка является «ядровой», если в радиусе eps у неё ≥ min_samples соседей
2. **Формирование кластеров** — ядровые точки на расстоянии ≤ eps друг от друга объединяются в один кластер
3. **Добавление пограничных точек** — точки, не являющиеся ядровыми, но находящиеся в eps-окрестности ядровой, присоединяются к её кластеру
4. **Обработка шума** — точки, не попавшие ни в один кластер, получают метку -1 (шум)

**Почему DBSCAN, а не K-Means:**
- Не нужно заранее знать число кластеров — DBSCAN определяет их сам
- Находит кластеры **произвольной формы** (K-Means — только сферические)
- Помечает изолированные точки как шум — полезно для выявления одиночных случаев, не связанных с очагами
- `eps=5000` означает, что инфицированные в радиусе 5 км считаются частью одного очага

**Влияние eps:**
- `eps=5000` (5 км) — больше мелких кластеров
- `eps=10000` (10 км) — кластеры объединяются, их становится меньше

### Почему GPU ускоряет DBSCAN

Основная вычислительная нагрузка — поиск соседей в радиусе eps для каждой точки. На CPU это O(n²) в наивной реализации. GPU-версия cuML использует оптимизированные структуры данных и параллельный поиск, что даёт значительное ускорение.

---

## 3. Логистическая регрессия — предсказание вероятности заражения

### Что мы делали

Обучили логистическую регрессию для предсказания вероятности заражения на основе возраста (`age`) и пола (`sex`). Затем разделили данные на обучающую и тестовую выборки для корректной оценки модели.

```python
logreg = cuml.LogisticRegression()
logreg.fit(gdf[['age', 'sex']], gdf['infected'])
```

### Как работает логистическая регрессия

Логистическая регрессия — алгоритм **обучения с учителем** (supervised) для задач **классификации**. Несмотря на слово «регрессия», он предсказывает **вероятность** принадлежности к классу.

**Математика:**
1. Вычисляется линейная комбинация: `z = w₁·age + w₂·sex + b`
   - `w₁, w₂` — коэффициенты (веса признаков), хранятся в `logreg.coef_`
   - `b` — смещение (bias), хранится в `logreg.intercept_`
2. Применяется сигмоид-функция: `P(infected=1) = 1 / (1 + e^(-z))`
   - Преобразует любое число в диапазон (0, 1) — это вероятность

**Результаты нашей модели:**
```
Coefficients: [age, sex] = [0.0149, 0.6957]
Intercept: -5.222
```

**Интерпретация:**
- Коэффициент age = 0.0149 — положительный, значит с увеличением возраста вероятность заражения **растёт**
- Коэффициент sex = 0.6957 — положительный, значит у пола=1 (женщины) вероятность выше
- Изменение пола с 0 на 1 даёт такой же эффект, как увеличение возраста на ~47 лет (0.6957/0.0149 ≈ 47)

### Предсказание вероятностей

```python
class_probs = logreg.predict_proba(gdf[['age', 'sex']])  # вероятности [P(0), P(1)]
gdf['risk'] = class_probs[1]  # вероятность заражения
```

`predict_proba` возвращает DataFrame с двумя столбцами: вероятность класса 0 и вероятность класса 1.

### Проверка связи признаков с заражением

```python
# Группировка по возрасту — видно, что пожилые заражаются чаще
age_groups = gdf[['age', 'infected']].groupby(['age']).mean()

# Группировка по полу — видно, что пол=1 заражается чаще
sex_groups = gdf[['sex', 'infected']].groupby(['sex']).mean()
```

### Train-Test Split — почему это важно

```python
X_train, X_test, y_train, y_test = cuml.train_test_split(
    gdf[['age', 'sex']], gdf['infected'], train_size=0.9
)
```

**Зачем делить данные:**
- **Переобучение (overfitting)** — модель может «запомнить» обучающие данные и плохо работать на новых
- Тестовая выборка (10% данных) имитирует «новые, невиданные данные»
- Если точность на тестовой выборке сопоставима с обучающей — модель обобщает хорошо

**Валидация:** разделили тестовую выборку на группы с предсказанным риском выше/ниже среднего и сравнили реальную долю заражённых — она коррелирует с предсказанными рисками.

---

## 4. K-Nearest Neighbors (KNN) — поиск ближайших дорожных узлов к больницам

### Что мы делали

Имея координаты дорожных узлов (~3.7 млн) и больниц (~1300), нашли 3 ближайших дорожных узла к каждой больнице. Это нужно для привязки больниц к дорожной сети (например, для маршрутизации).

```python
knn = cuml.NearestNeighbors(n_neighbors=3)

road_locs = road_nodes[['east', 'north']]
knn.fit(road_locs)                        # «запоминаем» все дорожные узлы

distances, indices = knn.kneighbors(
    hospitals[['easting', 'northing']], 3  # для каждой больницы найти 3 ближайших
)
```

### Как работает KNN

KNN — один из простейших алгоритмов, но на практике очень полезный.

**Алгоритм:**
1. **Fit** — сохранить все точки обучающего набора (дорожные узлы)
2. **Query** — для каждой новой точки (больницы) найти K ближайших сохранённых точек

**Результат:**
- `distances` — DataFrame, где строка i содержит расстояния от i-й больницы до её 3 ближайших узлов
- `indices` — DataFrame с индексами этих узлов в массиве `road_nodes`

**Пример:**
```
Больница #10: координаты (260713, 56303)
Ближайшие узлы:
  #118559: (260698, 56323) — ≈25 м
  #118560: (260723, 56208) — ≈95 м
  #118678: (260540, 56105) — ≈247 м
```

**Почему GPU ускоряет KNN:**
Наивный KNN на CPU для 1300 больниц × 3.7 млн узлов = ~4.8 млрд расчётов расстояний. cuML использует оптимизированные алгоритмы (brute-force с параллелизмом GPU или ball-tree), что даёт ускорение в десятки раз.

**Важно:** порядок столбцов при `fit` и `kneighbors` должен совпадать! Если обучали на `['east', 'north']`, то и запрос должен быть `['easting', 'northing']` (восток, север).

---

## 5. XGBoost — градиентный бустинг на GPU

### Что мы делали

Обучили XGBoost-модель для предсказания вероятности заражения, используя 4 признака: `age`, `sex`, `northing`, `easting`. В отличие от логистической регрессии, XGBoost может улавливать **нелинейные** зависимости (например, пространственные закономерности распространения вируса).

### Подготовка данных

```python
from cuml.model_selection import train_test_split

gdf = cudf.read_csv('./data/clean_uk_pop_full.csv',
                     usecols=['age', 'sex', 'northing', 'easting', 'infected'])

x_train, x_test, y_train, y_test = train_test_split(
    gdf[['age', 'sex', 'northing', 'easting']], gdf['infected']
)
del(gdf)  # освобождаем GPU-память — данные уже скопированы в train/test
```

**Важно:** после split удаляем оригинальные данные, чтобы освободить GPU-память для обучения. GPU-память ограничена (~15 ГБ на Tesla T4), и XGBoost создаёт значительные промежуточные структуры.

### Настройка параметров

```python
params = {
    'max_depth': 8,               # макс. глубина каждого дерева
    'max_leaves': 2**8,           # макс. число листьев в дереве
    'device': 'cuda',             # обучение на GPU
    'tree_method': 'hist',        # гистограммный метод построения деревьев
    'objective': 'binary:logistic', # бинарная классификация → вероятности
    'grow_policy': 'lossguide',   # рост дерева по уменьшению потерь
    'eval_metric': 'logloss',     # метрика — логарифмические потери
    'subsample': '0.8'            # каждое дерево обучается на 80% данных
}
```

**Ключевые параметры:**
- `device: 'cuda'` — критически важен для GPU-ускорения
- `tree_method: 'hist'` — гистограммный метод, эффективный на GPU (группирует значения в бины, а не перебирает каждое)
- `objective: 'binary:logistic'` — выход модели — вероятность заражения (0..1)
- `subsample: 0.8` — случайная подвыборка 80% для каждого дерева — уменьшает переобучение

### Обучение модели

```python
dtrain = xgb.DMatrix(x_train, y_train)  # специальный формат XGBoost
model = xgb.train(params, dtrain, num_boost_round=100)
```

**DMatrix** — высокоэффективная структура данных XGBoost. Данные передаются напрямую из cuDF в DMatrix **без копирования на CPU**.

**num_boost_round=100** — строится 100 последовательных деревьев. Каждое следующее дерево исправляет ошибки предыдущих.

**Производительность:**
- GPU: ~17.4 сек на 43.8 млн строк
- CPU: ~62 сек (в 3.5 раза медленнее)

### Как работает XGBoost (Gradient Boosting)

XGBoost — это **ансамбль деревьев решений**, где каждое следующее дерево обучается на ошибках предыдущих.

**Алгоритм:**
1. Начать с постоянного предсказания (например, средней вероятности)
2. Вычислить **остатки** — разницу между реальными и предсказанными значениями
3. Обучить новое дерево на этих остатках
4. Добавить предсказания нового дерева к общей модели (с коэффициентом обучения)
5. Повторить шаги 2–4 `num_boost_round` раз

Итоговое предсказание = сумма предсказаний всех 100 деревьев.

**Почему XGBoost лучше логистической регрессии для этой задачи:**
- Логистическая регрессия предполагает **линейную** связь между признаками и исходом
- XGBoost может выучить, что в определённом географическом регионе заражение выше — это **нелинейная** пространственная зависимость
- Подтверждение: `plot_importance` показал, что `easting` и `northing` — самые важные признаки (выше age и sex)

### Анализ модели

**Важность признаков (Feature Importance):**
```python
xgb.plot_importance(model)
```
F-score показывает, как часто признак используется для разбиения в деревьях. Чем выше — тем важнее. Результат: `easting > northing > age > sex`.

**Визуализация дерева:**
```python
xgb.plot_tree(model, num_trees=0, rankdir='LR')
```
Можно увидеть конкретные решения: «если easting < 300000, идём влево; иначе — вправо». Каждый лист содержит вклад в итоговое предсказание.

**Важно:** отдельные деревья дают небольшие коррекции — сила XGBoost в агрегации сотен «слабых» деревьев в «сильную» модель.

### Предсказание и оценка

```python
dtest = xgb.DMatrix(x_test)
y_pred = model.predict(dtest)  # ~466 мс на 11 млн строк
```

**Оценка через ROC-AUC:**
```python
from sklearn.metrics import roc_curve, auc

false_pos_rate, true_pos_rate, thresholds = roc_curve(y_test_cpu, y_pred)
auc_result = auc(false_pos_rate, true_pos_rate)
```

- **ROC-кривая** — график зависимости True Positive Rate от False Positive Rate при разных порогах
- **AUC** (Area Under Curve) — площадь под ROC-кривой. 0.5 = случайное угадывание, 1.0 = идеальная модель
- Чем ближе AUC к 1.0, тем лучше модель различает заражённых и здоровых

---

## 6. Triton Inference Server — развёртывание модели

### Что мы делали

Взяли обученную XGBoost-модель и развернули её в NVIDIA Triton Inference Server — промышленном сервере для обслуживания ML-моделей. Затем отправляли запросы через клиент и анализировали производительность.

### Зачем нужен Triton

В реальных приложениях модель должна работать как **сервис**: принимать HTTP/gRPC-запросы с данными и возвращать предсказания. Triton решает задачи:
- Автоматическая обработка входящих запросов
- Батчинг (объединение нескольких запросов в один пакет для эффективности)
- Поддержка нескольких моделей и версий одновременно
- Мониторинг метрик (latency, throughput, GPU usage)

### Подготовка модели

**1. Загрузка обученной модели:**
```python
model = xgb.Booster({'nthread': 4})
model.load_model('xgboost_model.json')
```

**2. Создание структуры директорий:**
```
models/
└── virus_prediction/    ← имя модели
    ├── 1/               ← номер версии
    │   └── xgboost.json ← файл модели
    └── config.pbtxt     ← конфигурация
```

Triton требует строгую структуру: имя модели → номер версии → файл. Можно держать несколько версий одной модели одновременно.

**3. Конфигурационный файл (`config.pbtxt`):**
```protobuf
backend: "fil"                    # FIL — Forest Inference Library (для деревьев)
max_batch_size: 32768             # макс. размер пакета
input [
  { name: "input__0", data_type: TYPE_FP32, dims: [ 4 ] }   # 4 признака (age, sex, northing, easting)
]
output [
  { name: "output__0", data_type: TYPE_FP32, dims: [ 1 ] }  # 1 вероятность
]
instance_group [{ kind: KIND_GPU }]   # выполнение на GPU
parameters [
  { key: "model_type", value: { string_value: "xgboost_json" } },
  { key: "output_class", value: { string_value: "false" } }   # вероятности, не классы
]
dynamic_batching { max_queue_delay_microseconds: 100 }   # динамический батчинг
```

**Ключевые настройки:**
- `backend: "fil"` — FIL (Forest Inference Library) — оптимизированный бэкенд для деревьев решений
- `max_batch_size: 32768` — сервер может обработать до 32768 примеров за один раз
- `dims: [4]` — 4 входных признака
- `output_class: "false"` — возвращать вероятности, а не метки классов
- `dynamic_batching` — Triton собирает несколько запросов в батч (ждёт до 100 мкс), повышая throughput

### Запуск Triton

Triton запускается как Docker-контейнер:
```bash
docker run --gpus=1 --rm \
  -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  -v /path/to/models:/models \
  nvcr.io/nvidia/tritonserver:xx.yy-py3 \
  tritonserver --model-repository=/models
```

Порты:
- 8000 — HTTP API
- 8001 — gRPC API
- 8002 — Prometheus метрики

Проверка готовности:
```bash
curl -v triton:8000/v2/health/ready          # → HTTP 200
curl -X POST http://triton:8000/v2/repository/index  # → список моделей
```

### Отправка запросов через Triton Client

```python
import tritonclient.grpc as triton_grpc

client = triton_grpc.InferenceServerClient(url='triton:8001')

# Подготовка входных данных
input_tensor = triton_grpc.InferInput("input__0", batched_data.shape, 'FP32')
input_tensor.set_data_from_numpy(batched_data)  # numpy float32

# Указание выхода
output = triton_grpc.InferRequestedOutput("output__0")

# Отправка запроса
response = client.infer("virus_prediction", [input_tensor], outputs=[output])
output_data = response.as_numpy("output__0")
```

Результат: 32768 предсказаний за **8 мс** (включая сетевую задержку).

**Верификация:** ROC-AUC для предсказаний через Triton совпадает с локальной моделью — развёртывание не исказило результаты.

### Анализ производительности с perf_analyzer

`perf_analyzer` — утилита от NVIDIA для нагрузочного тестирования:

```bash
# Базовый тест: 1 запрос за раз, batch_size=1
perf_analyzer -m virus_prediction -u "triton:8000"
# Результат: ~2294 infer/sec, avg latency 432 мкс

# Продвинутый тест: batch=8, concurrency 2→8
perf_analyzer --collect-metrics -m virus_prediction -u "triton:8000" \
  -b 8 --concurrency-range 2:8:2
# Результат: ~156171 infer/sec при concurrency=8
```

**Ключевые метрики:**
- **Throughput** — количество предсказаний в секунду
- **Latency** — время ответа (avg, p50, p90, p95, p99)
- **Concurrency** — число одновременных подключений

**Почему throughput растёт с concurrency:**
При 1 подключении Triton простаивает между получением ответа клиентом и отправкой нового запроса. С несколькими подключениями сервер перекрывает обработку одного запроса с коммуникацией другого — Pipeline эффект.

**GPU-метрики** (`--collect-metrics`): утилизация GPU, потребление энергии, использование памяти.

### Model Analyzer

Отдельный инструмент Triton, который автоматически перебирает конфигурации (batch_size, concurrency, instance_count) и находит оптимальные параметры для максимального throughput.

---

## 7. Multi-GPU K-Means с Dask

### Что мы делали

Масштабировали K-Means на несколько GPU через Dask. Данные — 5-кратно увеличенный датасет координат населения, разбитый на части для распределённого чтения.

### Настройка кластера

```python
from dask.distributed import Client
from dask_cuda import LocalCUDACluster

cluster = LocalCUDACluster(ip=IPADDR)
client = Client(cluster)
```

`LocalCUDACluster` создаёт один Dask-worker на каждый GPU. На машине с 4 GPU → 4 worker'а, каждый со своей GPU-памятью.

### Загрузка данных

```python
import dask_cudf
ddf = dask_cudf.read_csv('./data/uk_pop5x_coords.csv', dtype=['float32', 'float32'])
```

`dask_cudf.read_csv` читает данные параллельно, распределяя партиции между GPU. Каждый worker хранит свою часть данных в своей GPU-памяти.

### Обучение

```python
from cuml.dask.cluster import KMeans

dkm = KMeans(n_clusters=20)
dkm.fit(ddf)  # ~1 мин 53 сек для 5x-датасета на 4 GPU
```

**Как это работает:**
1. Каждый GPU-worker вычисляет расстояния от своих точек до текущих центроидов
2. Каждый worker вычисляет локальные суммы и количества для обновления центроидов
3. Результаты агрегируются (Reduce) для получения новых глобальных центроидов
4. Новые центроиды рассылаются всем worker'ам
5. Повторяется до сходимости

### Предсказание и анализ

```python
cluster_centers = dkm.cluster_centers_
cluster_centers.columns = ddf.columns

# Найти самый южный кластер
south_idx = cluster_centers.nsmallest(1, 'northing').index[0]

# Предсказать метки для всех данных
labels = dkm.predict(ddf)

# Посчитать число людей в самом южном кластере
count = labels[labels == south_idx].compute().shape[0]
```

**Важно:** `dkm.predict(ddf)` возвращает ленивый (lazy) результат. `.compute()` запускает реальные вычисления и собирает результат.

### Зачем Multi-GPU

- Датасет 5x (~250 млн строк) может не поместиться в память одного GPU
- Распределение вычислений по 4 GPU ускоряет обучение
- Dask автоматически управляет партиционированием и коммуникацией
- API практически идентичен single-GPU cuML — минимальные изменения кода

---

## Сводная таблица алгоритмов

| Алгоритм | Тип | Задача | Ключевые параметры | Когда использовать |
|---|---|---|---|---|
| **K-Means** | Unsupervised | Кластеризация | `n_clusters` | Число кластеров известно, нужны равномерные группы |
| **DBSCAN** | Unsupervised | Кластеризация | `eps`, `min_samples` | Число кластеров неизвестно, кластеры произвольной формы |
| **Logistic Regression** | Supervised | Классификация | — | Линейные зависимости, интерпретируемость |
| **KNN** | — | Поиск соседей | `n_neighbors` | Поиск ближайших объектов, привязка к сетке |
| **XGBoost** | Supervised | Классификация/регрессия | `max_depth`, `n_rounds` | Нелинейные зависимости, максимальная точность |

---

## Вопросы и ответы

**1. Чем K-Means отличается от DBSCAN? Когда использовать какой?**

K-Means требует заранее задать число кластеров K и создаёт сферические кластеры одинакового размера. DBSCAN не требует задания числа кластеров — он определяет их по плотности данных, может находить кластеры произвольной формы и помечает изолированные точки как шум. K-Means подходит, когда мы знаем, сколько групп нужно (например, 5 складов), а DBSCAN — когда ищем естественные скопления (например, очаги заражения).

**2. Что означает параметр `eps` в DBSCAN и как его выбрать?**

`eps` — это максимальное расстояние между соседними точками, которые могут принадлежать одному кластеру. В нашем случае `eps=5000` означает 5 км, так как координаты в метрах. Если eps слишком маленький — много мелких кластеров и шума. Если слишком большой — кластеры сливаются. Выбирать нужно исходя из предметной области: для поиска очагов заражения разумно, чтобы люди в радиусе 5 км считались частью одного очага.

**3. Что такое коэффициенты логистической регрессии и как их интерпретировать?**

Коэффициенты (`coef_`) показывают вес каждого признака в предсказании. Положительный коэффициент означает, что увеличение признака повышает вероятность положительного исхода (заражения). Например, коэффициент age=0.015 значит, что с каждым годом возраста вероятность заражения немного растёт. Коэффициент sex=0.696 значит, что пол=1 даёт такой же прирост риска, как увеличение возраста на 47 лет. `intercept_` — это смещение, базовый уровень логита.

**4. Зачем делить данные на обучающую и тестовую выборки?**

Чтобы оценить, как модель работает на данных, которые она не видела при обучении. Без такого разделения модель может переобучиться — «запомнить» обучающие данные и давать отличные результаты на них, но плохие на новых данных. Мы берём 90% данных для обучения и 10% для теста. Если метрики на тесте сопоставимы с обучающими — модель хорошо обобщает.

**5. Почему XGBoost лучше подходит для данных с координатами, чем логистическая регрессия?**

Логистическая регрессия предполагает линейную связь: чем больше easting, тем больше/меньше вероятность. Но заражение может быть высоким в конкретных районах — это нелинейная зависимость. XGBoost строит деревья решений, которые могут вырезать прямоугольные области пространства: «если easting между 300000 и 400000 И northing между 200000 и 300000 — вероятность высокая». Подтверждение: feature importance показал, что easting и northing — самые важные признаки.

**6. Что такое DMatrix в XGBoost и зачем он нужен?**

DMatrix — это специальная оптимизированная структура данных XGBoost. Она эффективнее, чем обычный DataFrame, за счёт внутреннего сжатия и организации данных для быстрого поиска лучших разбиений. Важно, что при использовании cuDF данные передаются в DMatrix напрямую из GPU-памяти без копирования на CPU. Это сохраняет преимущества GPU-ускорения.

**7. Что показывает ROC-кривая и AUC-метрика?**

ROC-кривая отображает компромисс между True Positive Rate (доля правильно найденных заражённых) и False Positive Rate (доля здоровых, ошибочно помеченных как заражённые) при разных порогах вероятности. AUC — площадь под этой кривой: 0.5 = модель не лучше случайного угадывания, 1.0 = идеальная модель. AUC удобна тем, что не зависит от выбора конкретного порога.

**8. Как KNN находит ближайшие дорожные узлы к больницам?**

На этапе `fit` модель запоминает координаты всех дорожных узлов (~3.7 млн). На этапе `kneighbors` для каждой больницы вычисляются расстояния до всех узлов, и возвращаются K ближайших (в нашем случае 3). Результат — два массива: `distances` (расстояния) и `indices` (индексы узлов). Важно, чтобы порядок столбцов при fit и kneighbors совпадал.

**9. Что такое Triton Inference Server и какую проблему он решает?**

Triton — сервер от NVIDIA для развёртывания ML-моделей в продакшене. Он решает проблему перехода от «модель обучена на моём ноутбуке» к «модель обслуживает тысячи запросов в секунду». Triton принимает HTTP/gRPC запросы, автоматически батчит их для эффективного использования GPU, поддерживает несколько моделей и версий, мониторит метрики. Без Triton пришлось бы писать весь этот инфраструктурный код вручную.

**10. Что такое dynamic batching в Triton и зачем он нужен?**

Dynamic batching — механизм, при котором Triton собирает несколько мелких запросов в один большой батч перед отправкой на GPU. Параметр `max_queue_delay_microseconds: 100` означает, что сервер ждёт до 100 мкс, собирая запросы. GPU работает эффективнее с большими батчами (параллелизм), поэтому обработка 8 запросов одним пакетом быстрее, чем 8 отдельных запросов. Это повышает throughput без увеличения latency.

**11. Почему throughput растёт с увеличением concurrency в perf_analyzer?**

При concurrency=1 между отправкой ответа и получением нового запроса сервер простаивает — это сетевая задержка. При concurrency>1 несколько запросов находятся «в полёте» одновременно: пока один обрабатывается, другой уже в очереди. Triton перекрывает вычисления с коммуникацией. В нашем тесте throughput вырос с ~2300 infer/sec (concurrency=1) до ~156000 infer/sec (concurrency=8, batch=8).

**12. Как FIL-бэкенд в Triton ускоряет инференс деревьев?**

FIL (Forest Inference Library) — специализированный бэкенд для ансамблей деревьев решений. Он загружает все деревья модели в GPU-память и обрабатывает множество примеров параллельно. Вместо последовательного прохода по каждому дереву для каждого примера, FIL батчит данные и обходит деревья параллельно на GPU. Это даёт огромное ускорение для моделей с сотнями деревьев.

**13. Как Dask масштабирует K-Means на несколько GPU?**

LocalCUDACluster создаёт по одному worker'у на каждый GPU. Данные распределяются между worker'ами через dask_cudf. При обучении каждый worker вычисляет расстояния и обновления для своей части данных (Map), затем результаты агрегируются для вычисления новых центроидов (Reduce). API идентичен single-GPU cuML — нужно лишь импортировать KMeans из cuml.dask.cluster вместо cuml.

**14. Что такое `predict_proba` и чем оно отличается от `predict`?**

`predict` возвращает метки классов (0 или 1): «заражён» или «не заражён», используя порог 0.5. `predict_proba` возвращает вероятности для каждого класса: например, [0.985, 0.015] означает 98.5% вероятность здоров, 1.5% — заражён. Для редких событий (заражение 1-2% популяции) `predict` бесполезен — почти все получат метку 0. `predict_proba` позволяет ранжировать людей по риску и выбирать свой порог.

**15. Зачем в XGBoost параметр `subsample=0.8`?**

Subsample означает, что каждое дерево обучается на случайных 80% обучающих данных. Это разновидность регуляризации — снижает переобучение, делая каждое дерево немного отличным от других. Аналогично тому, как в случайном лесу каждое дерево видит подмножество данных. Если subsample=1.0, каждое дерево видит все данные, что увеличивает риск переобучения. Значение 0.8 — хороший баланс между точностью и обобщающей способностью.
